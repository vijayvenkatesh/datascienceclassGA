{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.read_csv(\"http://data.princeton.edu/wws509/datasets/salary.dat\", sep='\\s+') #open data set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sx</th>\n",
        "      <th>rk</th>\n",
        "      <th>yr</th>\n",
        "      <th>dg</th>\n",
        "      <th>yd</th>\n",
        "      <th>sl</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   male</td>\n",
        "      <td> full</td>\n",
        "      <td> 25</td>\n",
        "      <td> doctorate</td>\n",
        "      <td> 35</td>\n",
        "      <td> 36350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   male</td>\n",
        "      <td> full</td>\n",
        "      <td> 13</td>\n",
        "      <td> doctorate</td>\n",
        "      <td> 22</td>\n",
        "      <td> 35350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   male</td>\n",
        "      <td> full</td>\n",
        "      <td> 10</td>\n",
        "      <td> doctorate</td>\n",
        "      <td> 23</td>\n",
        "      <td> 28200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> female</td>\n",
        "      <td> full</td>\n",
        "      <td>  7</td>\n",
        "      <td> doctorate</td>\n",
        "      <td> 27</td>\n",
        "      <td> 26775</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   male</td>\n",
        "      <td> full</td>\n",
        "      <td> 19</td>\n",
        "      <td>   masters</td>\n",
        "      <td> 30</td>\n",
        "      <td> 33696</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "       sx    rk  yr         dg  yd     sl\n",
        "0    male  full  25  doctorate  35  36350\n",
        "1    male  full  13  doctorate  22  35350\n",
        "2    male  full  10  doctorate  23  28200\n",
        "3  female  full   7  doctorate  27  26775\n",
        "4    male  full  19    masters  30  33696"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as sm #New project - stats packages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.ols(\"sl ~ sx + rk \", data).fit()  # Y depends on X; Y = sl, X = sx if you do sl~sx-1 it gets rid of constant value\n",
      "#Don't generally want to get rid of it\n",
      "#Intercept = base case"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.758</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.743</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.16</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Thu, 09 Jan 2014</td> <th>  Prob (F-statistic):</th> <td>7.89e-15</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>20:07:38</td>     <th>  Log-Likelihood:    </th> <td> -488.03</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   984.1</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   991.9</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th>       <td> 1.729e+04</td> <td>  892.510</td> <td>   19.367</td> <td> 0.000</td> <td> 1.55e+04  1.91e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sx[T.male]</th>      <td>  869.4545</td> <td>  980.501</td> <td>    0.887</td> <td> 0.380</td> <td>-1101.975  2840.884</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.associate]</th> <td> 5145.0455</td> <td> 1109.035</td> <td>    4.639</td> <td> 0.000</td> <td> 2915.181  7374.910</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.full]</th>      <td> 1.168e+04</td> <td> 1003.575</td> <td>   11.636</td> <td> 0.000</td> <td> 9659.927  1.37e+04</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td> 8.357</td> <th>  Durbin-Watson:     </th> <td>   1.988</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.015</td> <th>  Jarque-Bera (JB):  </th> <td>   7.501</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.842</td> <th>  Prob(JB):          </th> <td>  0.0235</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 3.793</td> <th>  Cond. No.          </th> <td>    4.56</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                     sl   R-squared:                       0.758\n",
        "Model:                            OLS   Adj. R-squared:                  0.743\n",
        "Method:                 Least Squares   F-statistic:                     50.16\n",
        "Date:                Thu, 09 Jan 2014   Prob (F-statistic):           7.89e-15\n",
        "Time:                        20:07:38   Log-Likelihood:                -488.03\n",
        "No. Observations:                  52   AIC:                             984.1\n",
        "Df Residuals:                      48   BIC:                             991.9\n",
        "Df Model:                           3                                         \n",
        "===================================================================================\n",
        "                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "-----------------------------------------------------------------------------------\n",
        "Intercept        1.729e+04    892.510     19.367      0.000      1.55e+04  1.91e+04\n",
        "sx[T.male]        869.4545    980.501      0.887      0.380     -1101.975  2840.884\n",
        "rk[T.associate]  5145.0455   1109.035      4.639      0.000      2915.181  7374.910\n",
        "rk[T.full]       1.168e+04   1003.575     11.636      0.000      9659.927  1.37e+04\n",
        "==============================================================================\n",
        "Omnibus:                        8.357   Durbin-Watson:                   1.988\n",
        "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                7.501\n",
        "Skew:                           0.842   Prob(JB):                       0.0235\n",
        "Kurtosis:                       3.793   Cond. No.                         4.56\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sal = 3339 * (are you male) + 21360\n",
      "#95 % confident interval\n",
      "#R-squared - howmuch of the variance is explained by the factors you've built. ranges from 0-1. Want it to be close to 1\n",
      "data.rk.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array(['full', 'associate', 'assistant'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model2 = sm.ols(\" sl ~ sx + rk + sx:rk\",data).fit() #Short hand instead of a + b + a:b is a*b\n",
      "model2 = sm.ols(\" sl ~ sx*rk + yd\",data).fit() # + C(yd) - force it to be a category \n",
      "model2.summary()\n",
      "#if goal is prediction - you may not care about interactions\n",
      "#sal = 17K + 340(are you male) + 4k(associate) + 11k (fulltime professor) + 15(male + associate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.782</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.753</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.90</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Thu, 09 Jan 2014</td> <th>  Prob (F-statistic):</th> <td>2.36e-13</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>20:21:22</td>     <th>  Log-Likelihood:    </th> <td> -485.33</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   984.7</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   998.3</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th>                  <td> 1.684e+04</td> <td> 1095.759</td> <td>   15.371</td> <td> 0.000</td> <td> 1.46e+04   1.9e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sx[T.male]</th>                 <td>  138.5790</td> <td> 1398.408</td> <td>    0.099</td> <td> 0.922</td> <td>-2677.960  2955.118</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.associate]</th>            <td>  572.6429</td> <td> 2823.070</td> <td>    0.203</td> <td> 0.840</td> <td>-5113.311  6258.597</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.full]</th>                 <td> 8645.2304</td> <td> 2169.020</td> <td>    3.986</td> <td> 0.000</td> <td> 4276.599   1.3e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sx[T.male]:rk[T.associate]</th> <td> 3622.3682</td> <td> 2819.668</td> <td>    1.285</td> <td> 0.205</td> <td>-2056.735  9301.471</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sx[T.male]:rk[T.full]</th>      <td> 1230.3900</td> <td> 2169.289</td> <td>    0.567</td> <td> 0.573</td> <td>-3138.782  5599.562</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>yd</th>                         <td>  134.0140</td> <td>   62.773</td> <td>    2.135</td> <td> 0.038</td> <td>    7.583   260.445</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td> 9.247</td> <th>  Durbin-Watson:     </th> <td>   1.988</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.010</td> <th>  Jarque-Bera (JB):  </th> <td>   9.268</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.758</td> <th>  Prob(JB):          </th> <td> 0.00971</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 4.407</td> <th>  Cond. No.          </th> <td>    198.</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                     sl   R-squared:                       0.782\n",
        "Model:                            OLS   Adj. R-squared:                  0.753\n",
        "Method:                 Least Squares   F-statistic:                     26.90\n",
        "Date:                Thu, 09 Jan 2014   Prob (F-statistic):           2.36e-13\n",
        "Time:                        20:21:22   Log-Likelihood:                -485.33\n",
        "No. Observations:                  52   AIC:                             984.7\n",
        "Df Residuals:                      45   BIC:                             998.3\n",
        "Df Model:                           6                                         \n",
        "==============================================================================================\n",
        "                                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "----------------------------------------------------------------------------------------------\n",
        "Intercept                   1.684e+04   1095.759     15.371      0.000      1.46e+04   1.9e+04\n",
        "sx[T.male]                   138.5790   1398.408      0.099      0.922     -2677.960  2955.118\n",
        "rk[T.associate]              572.6429   2823.070      0.203      0.840     -5113.311  6258.597\n",
        "rk[T.full]                  8645.2304   2169.020      3.986      0.000      4276.599   1.3e+04\n",
        "sx[T.male]:rk[T.associate]  3622.3682   2819.668      1.285      0.205     -2056.735  9301.471\n",
        "sx[T.male]:rk[T.full]       1230.3900   2169.289      0.567      0.573     -3138.782  5599.562\n",
        "yd                           134.0140     62.773      2.135      0.038         7.583   260.445\n",
        "==============================================================================\n",
        "Omnibus:                        9.247   Durbin-Watson:                   1.988\n",
        "Prob(Omnibus):                  0.010   Jarque-Bera (JB):                9.268\n",
        "Skew:                           0.758   Prob(JB):                      0.00971\n",
        "Kurtosis:                       4.407   Cond. No.                         198.\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from  sklearn import linear_model\n",
      "from patsy import dmatrices #Patsy only has one developer - Create matrix yourself\n",
      "\n",
      "y, X = dmatrices('sl~sx + yr + rk', data= data, return_type='dataframe')\n",
      "X.head()          \n",
      "model3 = linear_model.LinearRegression()\n",
      "model3.fit(X,y)\n",
      "model3.score(X,y)\n",
      "#Build a matrix for each category and build it\n",
      "#model.predict()\n",
      "# sklearn.metrics - MAE\n",
      "# score = R2 value\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.8461760134902937"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model3.intercept_\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sl</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 36350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 35350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 28200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 26775</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 33696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 28516</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 24900</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 31909</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 31850</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 32850</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 27025</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 24750</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 28200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 23712</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 25748</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 29342</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 31114</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 24742</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 22906</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 24450</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 19175</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 20525</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 27959</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> 38045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 24832</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> 25400</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 24800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 25500</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td> 26182</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td> 23725</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td> 21600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td> 23300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td> 23713</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td> 20690</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> 22450</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> 20850</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td> 18304</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td> 17095</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td> 16700</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td> 17600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td> 18075</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> 18000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td> 20999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td> 17250</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td> 16500</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td> 16094</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td> 16150</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td> 15350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td> 16244</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td> 16686</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td> 15000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td> 20300</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "       sl\n",
        "0   36350\n",
        "1   35350\n",
        "2   28200\n",
        "3   26775\n",
        "4   33696\n",
        "5   28516\n",
        "6   24900\n",
        "7   31909\n",
        "8   31850\n",
        "9   32850\n",
        "10  27025\n",
        "11  24750\n",
        "12  28200\n",
        "13  23712\n",
        "14  25748\n",
        "15  29342\n",
        "16  31114\n",
        "17  24742\n",
        "18  22906\n",
        "19  24450\n",
        "20  19175\n",
        "21  20525\n",
        "22  27959\n",
        "23  38045\n",
        "24  24832\n",
        "25  25400\n",
        "26  24800\n",
        "27  25500\n",
        "28  26182\n",
        "29  23725\n",
        "30  21600\n",
        "31  23300\n",
        "32  23713\n",
        "33  20690\n",
        "34  22450\n",
        "35  20850\n",
        "36  18304\n",
        "37  17095\n",
        "38  16700\n",
        "39  17600\n",
        "40  18075\n",
        "41  18000\n",
        "42  20999\n",
        "43  17250\n",
        "44  16500\n",
        "45  16094\n",
        "46  16150\n",
        "47  15350\n",
        "48  16244\n",
        "49  16686\n",
        "50  15000\n",
        "51  20300"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "y = np.array(y).reshape(y.shape[0]) #Bug in scikit learn\n",
      "\n",
      "l1 = linear_model.LassoCV(alphas=[0.01,0.1,10])      #Need to know alpha. #CV is cross validation version\n",
      "#l2 = linear_model.RidgeCV(alphas=[0.01,0.1,10])\n",
      "l1.fit(X,y)\n",
      "#y.shape - Vector - 52 columns, 1 matrix - wants a vector and not a one column matrix\n",
      "# y = np.array(y).reshape(np.shape[0])\n",
      "y.shape\n",
      "l1."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "(52,)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#l2 = linear_model.Ridge(alpha=10000)\n",
      "#l2.fit(X,y)\n",
      "#l2.coef_\n",
      "#MAE - Mean absolute value - Sum of the absolute value of the differences y and y.hat(predicted) - Total error\n",
      "#MSE - Mean squared value - Mean squared optimizes for being wrong more often than not. \n",
      "# Compare R2 value + MAE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}